{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNbTmSp+ugucTXoZ4uCxz2s"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"5zec-PO7lmPi"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["Exercício: Seleção de Variáveis com Pipeline e Forward Selection\n","Use o dataset diabetes do sklearn.datasets para avaliar como o desempenho de uma regressão linear varia com diferentes números de variáveis.\n","\n","Instruções\n","Carregue o dataset usando load_diabetes().\n","\n","Divida os dados em treino (60%), validação (20%) e teste (20%) usando train_test_split().\n","\n","Para cada quantidade de variáveis de 1 até o total de variáveis:\n","\n","Crie um Pipeline contendo dois passos:\n","Seleção de variáveis com SequentialFeatureSelector() usando:\n","estimator=LinearRegression()\n","direction='forward'\n","cv=5\n","n_features_to_select=k (o número atual de variáveis no loop)\n","Um modelo LinearRegression().\n","Ajuste o pipeline na base de treino.\n","Calcule o MSE na base de validação.\n","Registre:\n","O número de variáveis usadas (k).\n","O MSE na validação.\n","A lista de variáveis selecionadas.\n","Organize os resultados em uma tabela.\n","\n","Faça um gráfico do MSE em função do número de variáveis.\n","\n","Esboço da função para criar o pipeline\n","pipe = Pipeline([\n","    ('selecao', SequentialFeatureSelector(\n","        estimator=LinearRegression(),\n","        n_features_to_select=n_variaveis,\n","        direction='forward',\n","        cv=5\n","    )),\n","    ('regressor', LinearRegression())\n","])\n","Exercício: Regularização com Ridge e Lasso\n","O objetivo deste exercício é analisar como a regularização afeta os coeficientes de uma regressão linear, utilizando os modelos Ridge e Lasso.\n","\n","Objetivos\n","Observar como os coeficientes variam conforme o parâmetro de regularização (alpha) aumenta.\n","Comparar o efeito da regularização nos modelos Ridge e Lasso.\n","Instruções\n","Carregue o dataset diabetes com a função load_diabetes da biblioteca sklearn.datasets.\n","\n","Divida os dados em treino (60%), validação (20%) e teste (20%) utilizando duas vezes a função train_test_split da biblioteca sklearn.model_selection.\n","\n","Crie uma sequência de valores de alpha usando np.logspace(-4, 2, 100), que gera 100 valores entre 10^-4 e 10^2 em escala logarítmica.\n","\n","Para cada valor de alpha, ajuste dois modelos utilizando a base de treino:\n","\n","Um modelo Ridge com Ridge(alpha=...).\n","Um modelo Lasso com Lasso(alpha=..., max_iter=10000).\n","Guarde os coeficientes de cada modelo para cada valor de alpha.\n","\n","Faça dois gráficos:\n","\n","Um gráfico dos coeficientes do Ridge em função de alpha.\n","Um gráfico dos coeficientes do Lasso em função de alpha.\n","O eixo x deve estar em escala logarítmica (plt.xscale('log')) e o eixo y representa os coeficientes.\n","\n","Pergunta\n","O que acontece com os coeficientes à medida que o parâmetro alpha aumenta? Compare os comportamentos do Ridge e do Lasso.\n","\n","Exercício: Regularização com Ridge, Lasso e Regressão Linear em Alta Dimensionalidade\n","O objetivo deste exercício é comparar como os modelos Ridge, Lasso e Regressão Linear se comportam em um problema de alta dimensionalidade, onde poucas variáveis são realmente relevantes.\n","\n","Objetivos\n","Observar como os coeficientes variam conforme o parâmetro de regularização (alpha) aumenta.\n","Comparar o efeito da regularização nos modelos Ridge e Lasso.\n","Analisar as diferenças entre regressão com e sem regularização.\n","Avaliar o desempenho dos modelos no conjunto de teste.\n","Instruções\n","Carregue o dataset dataset.csv utilizando a função pd.read_csv() da biblioteca pandas.\n","\n","Separe as variáveis explicativas (X1, X2, ..., X500) da variável resposta (y).\n","\n","Divida os dados em treino (60%), validação (20%) e teste (20%) utilizando duas vezes a função train_test_split da biblioteca sklearn.model_selection.\n","\n","Crie uma sequência de valores de alpha utilizando np.linspace(0.01, 1000, 200), que gera 200 valores igualmente espaçados entre 0.01 e 1000.\n","\n","Para cada valor de alpha, ajuste dois modelos utilizando a base de treino:\n","\n","Um modelo Ridge com Ridge(alpha=...).\n","Um modelo Lasso com Lasso(alpha=..., max_iter=10000).\n","Para cada modelo e valor de alpha, calcule o erro quadrático médio (MSE) no conjunto de validação utilizando a função mean_squared_error da biblioteca sklearn.metrics.\n","\n","Encontre o melhor alpha para cada modelo (aquele que minimiza o MSE de validação).\n","\n","Avalie o erro quadrático médio (MSE) desses modelos no conjunto de teste.\n","\n","Extraia os coeficientes dos três modelos utilizando o atributo .coef_.\n","\n","Plote um gráfico de barras com os 10 coeficientes de maior módulo para cada modelo.\n","\n","Perguntas\n","O que acontece com os coeficientes à medida que o parâmetro alpha aumenta?\n","Qual modelo realiza seleção de variáveis? Qual apenas suaviza os coeficientes?\n","Como se comportam os coeficientes do modelo de regressão linear comparado aos modelos regularizados?\n","Qual modelo obteve melhor desempenho no conjunto de teste? Isso faz sentido dado o cenário de alta dimensionalidade?"],"metadata":{"id":"uJHjmlH-lyKO"}}]}